{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment 3: Estimating a Search Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Applied Econometrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conor Bayliss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we are going to estimate the parameters of the search model for each demographic group *individually*. That is, you will *not* impose the parametrics restrictions that mapped demographics $X$ to deeper parameters using the `NamedTuples` I used last week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, QuadGK, Distributions, CSV, DataFrames, DataFramesMeta, Statistics, Optim, FastGaussQuadrature, ForwardDiff, Roots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Adapting Code for Automatic Differentiation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`QuadGK` doesn't play nicely with automatic differentiation since it adjusts the number of nodes adaptively. One solution is to use a fixed number of nodes and weights with `FastGaussQuadrature`. Here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.235638422590369"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function integrandGL(f,a,b;num_nodes = 10)\n",
    "    nodes, weights = gausslegendre(num_nodes)\n",
    "    ∫f = 0.\n",
    "    for k in eachindex(nodes)\n",
    "        x = (a+b)/2 + (b-a)/2*nodes[k]\n",
    "        ∫f += weights[k]*f(x)\n",
    "    end\n",
    "    return ∫f*(b-a)/2\n",
    "end\n",
    "\n",
    "dS(x;F,β,δ) = (1-cdf(F,x)) / (1-β*(1-δ))\n",
    "res_wage(wres, b,λ,δ,β,F) = wres - b - β * λ * integrandGL(x -> dS(x;F,β,δ),wres,quantile(F,0.999))\n",
    "ForwardDiff.derivative(wres -> res_wage(wres,0.,0.5,0.03,0.99,LogNormal(0.,1.)),1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Re-writing the model solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, we're going to re-write the model solution using this new integration routine. We will also use `Roots` to solve for the reservation wage in a way that will also play nicely with `ForwardDiff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4400135335598148"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_wage_solution(wres, b,λ,δ,β,F::Distribution) = wres - b - β * λ * integrandGL(x -> dS(x;F,β,δ),wres,quantile(F,0.999))\n",
    "pars = (;b=-5., λ=0.45,δ=0.03,β=0.99, F=LogNormal(1.,1.))\n",
    "\n",
    "function solve_res_wage(b,λ,δ,β,F)\n",
    "    return find_zero(wres -> res_wage_solution(wres,b,λ,δ,β,F),eltype(b)(4.))\n",
    "end\n",
    "\n",
    "solve_res_wage(0.,0.4,0.03,0.995,LogNormal())\n",
    "ForwardDiff.derivative(x -> solve_res_wage(x,0.4,0.03,0.995,LogNormal()),0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cleaning the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data cleaning is mostly the same as in **Assignment 2**. We add a function which pulls a `NamedTuple` out for a specific demographic group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(logwage = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.516124491189194, 3.872798692268385, 0.0  …  2.7762279256323206, 0.0, 0.0, 0.0, 2.976307324928243, 0.0, 0.0, 3.410759848526933, 0.0, 0.0], wage_missing = Bool[1, 1, 1, 1, 1, 1, 1, 0, 0, 1  …  0, 1, 1, 1, 0, 1, 1, 0, 1, 1], E = Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], tU = [231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0  …  231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = CSV.read(\"C:\\\\Users\\\\bayle\\\\Documents\\\\Github\\\\metrics\\\\hw2\\\\data\\\\cps_00019.csv\",DataFrame)\n",
    "data = @chain data begin\n",
    "    @transform :E = :EMPSTAT.<21\n",
    "    @transform @byrow :wage = begin\n",
    "        if :PAIDHOUR==0\n",
    "            return missing\n",
    "        elseif :PAIDHOUR==2\n",
    "            if :HOURWAGE<99.99 && :HOURWAGE>0\n",
    "                return :HOURWAGE\n",
    "            else\n",
    "                return missing\n",
    "            end\n",
    "        elseif :PAIDHOUR==1\n",
    "            if :EARNWEEK>0 && :UHRSWORKT<997 && :UHRSWORKT>0\n",
    "                return :EARNWEEK / :UHRSWORKT\n",
    "            else\n",
    "                return missing\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @subset :MONTH.==1\n",
    "    @select :AGE :SEX :RACE :EDUC :wage :E :DURUNEMP\n",
    "    @transform begin\n",
    "        :bachelors = :EDUC.>=111\n",
    "        :nonwhite = :RACE.!=100 \n",
    "        :female = :SEX.==2\n",
    "        :DURUNEMP = round.(:DURUNEMP .* 12/52)\n",
    "    end\n",
    "end\n",
    "\n",
    "# the whole dataset in a named tuple\n",
    "wage_missing = ismissing.(data.wage)\n",
    "wage = coalesce.(data.wage,1.)\n",
    "N = length(data.AGE)\n",
    "X = [ones(N) data.bachelors data.female data.nonwhite]\n",
    "# create a named tuple with all variables to conveniently pass to the log-likelihood:\n",
    "d = (;logwage = log.(wage),wage_missing,E = data.E,tU = data.DURUNEMP, X) #<- you will need to add your demographics as well.\n",
    "\n",
    "function get_data(data,C,F,R)\n",
    "    data = @subset data :bachelors.==C :female.==F :nonwhite.==R\n",
    "    wage_missing = ismissing.(data.wage)\n",
    "    wage = coalesce.(data.wage,1.)\n",
    "    N = length(data.AGE)\n",
    "    # create a named tuple with all variables to conveniently pass to the log-likelihood:\n",
    "    return d = (;logwage = log.(wage),wage_missing,E = data.E,tU = data.DURUNEMP) \n",
    "end\n",
    "\n",
    "dx = get_data(data,1,0,0) #<- data for white men with a college degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix $\\sigma_{\\zeta}$ (the standard deviation of measurement error in log wages) to 0.05. Following your work from last week (and recitation this week) write a function that calculates the log-likelihood of a single month of data from the CPS given $(h,\\delta,\\mu,\\sigma,w^*)$ where $w^*$ is the reservation wage and $h =$ $\\lambda$ x $(1-F_W(w^*;\\mu,\\sigma))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the log-likelihood to get maximum likelihood estimates of $(\\hat{h},\\hat{\\delta},\\hat{\\mu},\\hat{\\sigma},\\hat{w^*})$ for *white men with a college degree*. What is the advantage of estimating $h$ and $w^*$ directly instead of $\\lambda$ and $b$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back out the implied maximum likelihood estimates of $\\hat{\\lambda}$ and $\\hat{b}$ as a function of the estimated parameters from **Part 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide an estimate of the asymptotic variance of $(\\hat{h},\\hat{\\delta},\\hat{\\mu},\\hat{\\sigma},\\hat{w^*})$ using the standard MLE formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the delta method implies that if $\\hat{\\delta}$ is asymptotically normal with asymptotic variance $V$ then the vector-values function $F(\\hat{\\delta})$ is also asymptotically normal with:\n",
    "$$\n",
    "\\sqrt{N}F((\\hat{\\theta})-F(\\theta)) \\xrightarrow{d} \\mathcal{N}(0,\\nabla_{\\theta'}FV\\nabla_{\\theta}F')\n",
    "$$\n",
    "Use this fact to estimate the asymptotic variance of $(\\hat{h},\\hat{\\delta},\\hat{\\mu},\\hat{\\sigma},\\hat{w^*},\\hat{\\lambda},\\hat{b})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now report all of your estimates and standard errors for this group. Repeat this exercise for each group.\n",
    "\n",
    "If we thought that the parametric relationship using $\\gamma$ from **Assignment 2** described the true values of the parameters for each group, how might we use these group-specific estimates to derive estimates of each $\\gamma$?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.1",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
