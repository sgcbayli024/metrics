{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment 3: Estimating a Search Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Applied Econometrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conor Bayliss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we are going to estimate the parameters of the search model for each demographic group *individually*. That is, you will *not* impose the parametrics restrictions that mapped demographics $X$ to deeper parameters using the `NamedTuples` I used last week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, QuadGK, Distributions, CSV, DataFrames, DataFramesMeta, Statistics, Optim, FastGaussQuadrature, ForwardDiff, Roots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Adapting Code for Automatic Differentiation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`QuadGK` doesn't play nicely with automatic differentiation since it adjusts the number of nodes adaptively. One solution is to use a fixed number of nodes and weights with `FastGaussQuadrature`. Here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.235638422590369"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function integrandGL(f,a,b;num_nodes = 10)\n",
    "    nodes, weights = gausslegendre(num_nodes)\n",
    "    ∫f = 0.\n",
    "    for k in eachindex(nodes)\n",
    "        x = (a+b)/2 + (b-a)/2*nodes[k]\n",
    "        ∫f += weights[k]*f(x)\n",
    "    end\n",
    "    return ∫f*(b-a)/2\n",
    "end\n",
    "\n",
    "dS(x;F,β,δ) = (1-cdf(F,x)) / (1-β*(1-δ))\n",
    "res_wage(wres, b,λ,δ,β,F) = wres - b - β * λ * integrandGL(x -> dS(x;F,β,δ),wres,quantile(F,0.999))\n",
    "ForwardDiff.derivative(wres -> res_wage(wres,0.,0.5,0.03,0.99,LogNormal(0.,1.)),1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Re-writing the model solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, we're going to re-write the model solution using this new integration routine. We will also use `Roots` to solve for the reservation wage in a way that will also play nicely with `ForwardDiff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4400135335598148"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_wage_solution(wres, b,λ,δ,β,F::Distribution) = wres - b - β * λ * integrandGL(x -> dS(x;F,β,δ),wres,quantile(F,0.999))\n",
    "pars = (;b=-5., λ=0.45,δ=0.03,β=0.99, F=LogNormal(1.,1.))\n",
    "\n",
    "function solve_res_wage(b,λ,δ,β,F)\n",
    "    return find_zero(wres -> res_wage_solution(wres,b,λ,δ,β,F),eltype(b)(4.))\n",
    "end\n",
    "\n",
    "solve_res_wage(0.,0.4,0.03,0.995,LogNormal())\n",
    "ForwardDiff.derivative(x -> solve_res_wage(x,0.4,0.03,0.995,LogNormal()),0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cleaning the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data cleaning is mostly the same as in **Assignment 2**. We add a function which pulls a `NamedTuple` out for a specific demographic group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof(dx) = @NamedTuple{logwage::Vector{Float64}, wage_missing::BitVector, E::BitVector, tU::Vector{Float64}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "@NamedTuple{logwage::Vector{Float64}, wage_missing::BitVector, E::BitVector, tU::Vector{Float64}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = CSV.read(\"C:\\\\Users\\\\bayle\\\\Documents\\\\Github\\\\metrics\\\\hw2\\\\data\\\\cps_00019.csv\",DataFrame)\n",
    "data = @chain data begin\n",
    "    @transform :E = :EMPSTAT.<21\n",
    "    @transform @byrow :wage = begin\n",
    "        if :PAIDHOUR==0\n",
    "            return missing\n",
    "        elseif :PAIDHOUR==2\n",
    "            if :HOURWAGE<99.99 && :HOURWAGE>0\n",
    "                return :HOURWAGE\n",
    "            else\n",
    "                return missing\n",
    "            end\n",
    "        elseif :PAIDHOUR==1\n",
    "            if :EARNWEEK>0 && :UHRSWORKT<997 && :UHRSWORKT>0\n",
    "                return :EARNWEEK / :UHRSWORKT\n",
    "            else\n",
    "                return missing\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @subset :MONTH.==1\n",
    "    @select :AGE :SEX :RACE :EDUC :wage :E :DURUNEMP\n",
    "    @transform begin\n",
    "        :bachelors = :EDUC.>=111\n",
    "        :nonwhite = :RACE.!=100 \n",
    "        :female = :SEX.==2\n",
    "        :DURUNEMP = round.(:DURUNEMP .* 12/52)\n",
    "    end\n",
    "end\n",
    "\n",
    "# the whole dataset in a named tuple\n",
    "wage_missing = ismissing.(data.wage)\n",
    "wage = coalesce.(data.wage,1.)\n",
    "N = length(data.AGE)\n",
    "X = [ones(N) data.bachelors data.female data.nonwhite]\n",
    "# create a named tuple with all variables to conveniently pass to the log-likelihood:\n",
    "d = (;logwage = log.(wage),wage_missing,E = data.E,tU = data.DURUNEMP, X) #<- you will need to add your demographics as well.\n",
    "\n",
    "function get_data(data,C,F,R)\n",
    "    data = @subset data :bachelors.==C :female.==F :nonwhite.==R\n",
    "    wage_missing = ismissing.(data.wage)\n",
    "    wage = coalesce.(data.wage,1.)\n",
    "    N = length(data.AGE)\n",
    "    # create a named tuple with all variables to conveniently pass to the log-likelihood:\n",
    "    return d = (;logwage = log.(wage),wage_missing,E = data.E,tU = data.DURUNEMP) \n",
    "end\n",
    "\n",
    "dx = get_data(data,1,0,0) #<- data for white men with a college degree\n",
    "@show typeof(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `dx` is our instance of the data for white men with a college degree. It is saved as a `NamedTuple`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fix $\\sigma_{\\zeta}$ (the standard deviation of measurement error in log wages) to 0.05. Following your work from last week (and recitation this week) write a function that calculates the log-likelihood of a single month of data from the CPS given $(h,\\delta,\\mu,\\sigma,w^*)$ where $w^*$ is the reservation wage and $h =$ $\\lambda$ x $(1-F_W(w^*;\\mu,\\sigma))$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us define $\\phi$ and $\\Phi$, the pdf and cdf respectively of a Normal distribution with mean $\\mu$ and standard deviation $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Φ (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ϕ(x,μ,σ) = pdf(Normal(μ,σ),x)\n",
    "Φ(x,μ,σ) = cdf(Normal(μ,σ),x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write a function for the log-likelihood of observed wages. Remember that we need to integrate out measurement error. Recall that the likelihood of an observed wage $W^o$ is:\n",
    "$$\n",
    "f(W^o|E,X) = \\int_{w^*} \\frac{\\phi(\\log(w);\\mu,\\sigma)}{1-\\Phi(\\log(w^*);\\mu,\\sigma)}\\phi(\\log(W^o)-w;\\sigma_\\zeta)dw\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logwage_likelihood (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function logwage_likelihood(logwage, F::Distribution, σζ,wres)\n",
    "    f(x) = pdf(F,x) / (1-cdf(F,wres)) * ϕ(logwage,log(x),σζ) \n",
    "    ub = quantile(F,0.9999)\n",
    "    return integrandGL(f,wres,ub)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have integrated out measurement error, let us get the log-likelihhod of a single observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_likelihood (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function log_likelihood(d::NamedTuple, pars::NamedTuple,n)\n",
    "    (;h,σζ,wres,F,δ) = pars\n",
    "    ll = 0.\n",
    "    if d.E[n]\n",
    "        ll += log(h) - log(h+δ)\n",
    "        if !d.wage_missing[n]\n",
    "            ll += logwage_likelihood(d.logwage[n],F,σζ,wres)\n",
    "        end\n",
    "    else\n",
    "        ll += log(δ) - log(h+δ)\n",
    "        ll += log(h) + d.tU[n] * log(1-h)\n",
    "    end\n",
    "    return ll\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us write a function which maps the vector x into parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit(x) = exp(x) / (1 + exp(x))\n",
    "logit_inv(x) = log(x/(1-x))\n",
    "function update(pars,x)\n",
    "    h = logit(x[1])\n",
    "    δ = logit(x[2])\n",
    "    μ = x[3]\n",
    "    σ = exp(x[4])\n",
    "    wres = exp(x[5])\n",
    "    F = LogNormal(μ,σ)\n",
    "    σζ = 0.05\n",
    "    β = 0.995\n",
    "    return (; pars..., h,δ,μ,σ,wres,F,σζ,β)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, iterate over the dataset and calculate the log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_likelihood_obj (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function log_likelihood_obj(d::NamedTuple, pars::NamedTuple,x)\n",
    "    pars = update(pars,x)\n",
    "    ll = 0.\n",
    "    for n in 1:length(d.logwage)\n",
    "        ll += log_likelihood(d,pars,n)\n",
    "    end\n",
    "    return ll / length(d.E)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Use the log-likelihood to get maximum likelihood estimates of $(\\hat{h},\\hat{\\delta},\\hat{\\mu},\\hat{\\sigma},\\hat{w^*})$ for *white men with a college degree*. What is the advantage of estimating $h$ and $w^*$ directly instead of $\\lambda$ and $b$?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass the above to `Optim`. Recall that `dx` is our instance of the data for white men with a college degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     1.566021e-01     9.112564e-02\n",
      " * time: 0.016000032424926758\n",
      "     1     1.428602e-01     2.854767e-01\n",
      " * time: 1.0740001201629639\n",
      "     2     1.242758e-01     5.083573e-01\n",
      " * time: 1.4249999523162842\n",
      "     3     1.191880e-01     1.703036e-01\n",
      " * time: 1.5130000114440918\n",
      "     4     1.084706e-01     1.057356e-01\n",
      " * time: 1.689000129699707\n",
      "     5     8.126498e-02     1.194761e-01\n",
      " * time: 2.008000135421753\n",
      "     6     6.202614e-02     1.685874e-01\n",
      " * time: 2.0959999561309814\n",
      "     7     4.691572e-02     2.470724e-01\n",
      " * time: 2.2829999923706055\n",
      "     8     4.636126e-02     5.545455e-02\n",
      " * time: 2.4600000381469727\n",
      "     9     4.538795e-02     2.810290e-02\n",
      " * time: 2.549999952316284\n",
      "    10     4.463113e-02     1.735994e-01\n",
      " * time: 2.7269999980926514\n",
      "    11     4.316592e-02     3.522844e-02\n",
      " * time: 2.8570001125335693\n",
      "    12     4.293745e-02     3.139161e-02\n",
      " * time: 2.99399995803833\n",
      "    13     4.288508e-02     1.917004e-02\n",
      " * time: 3.1410000324249268\n",
      "    14     4.285242e-02     6.529510e-03\n",
      " * time: 3.2780001163482666\n",
      "    15     4.244827e-02     5.338491e-02\n",
      " * time: 3.4539999961853027\n",
      "    16     4.211665e-02     4.365717e-02\n",
      " * time: 3.5899999141693115\n",
      "    17     4.207630e-02     4.896747e-03\n",
      " * time: 3.7260000705718994\n",
      "    18     4.204468e-02     1.442213e-02\n",
      " * time: 3.864000082015991\n",
      "    19     4.202671e-02     4.615538e-03\n",
      " * time: 4.0\n",
      "    20     4.202050e-02     1.198159e-02\n",
      " * time: 4.13100004196167\n",
      "    21     4.201065e-02     2.041690e-03\n",
      " * time: 4.271000146865845\n",
      "    22     4.199637e-02     1.222502e-03\n",
      " * time: 4.417999982833862\n",
      "    23     4.199441e-02     4.606048e-03\n",
      " * time: 4.555999994277954\n",
      "    24     4.199411e-02     9.244151e-05\n",
      " * time: 4.694000005722046\n",
      "    25     4.199410e-02     2.433193e-07\n",
      " * time: 4.83299994468689\n",
      "    26     4.199410e-02     2.962284e-07\n",
      " * time: 4.9690001010894775\n",
      "    27     4.199410e-02     2.078074e-09\n",
      " * time: 5.101999998092651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(σζ = 0.05, β = 0.995, h = 0.17641764362085174, δ = 0.0038283722601471946, μ = 2.2091536420274718, σ = 1.103509994766977, wres = 21.80490807041903, F = LogNormal{Float64}(μ=2.2091536420274718, σ=1.103509994766977))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0 = [logit_inv(0.5),logit_inv(0.03),2.,log(1.),log(5.)]\n",
    "pars = (;σζ=0.05,β=0.995)\n",
    "log_likelihood_obj(dx,pars,x0)\n",
    "res = optimize(x -> -log_likelihood_obj(dx,pars,x),x0,BFGS(),Optim.Options(show_trace=true))\n",
    "pars = update(pars,res.minimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, our estimated parameters are, to 5 decimal places:\n",
    "\n",
    "| Parameter | Estimate | \n",
    "| -------- | -------- | \n",
    "| $\\hat{h}$   | 0.17642    |\n",
    "| $\\hat{\\delta}$    | 0.00383    | \n",
    "| $\\hat{\\mu}$    | 2.20915    | \n",
    "| $\\hat{\\sigma}$    | 1.10351    | \n",
    "| $w^*$    | 21.80491    | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Back out the implied maximum likelihood estimates of $\\hat{\\lambda}$ and $\\hat{b}$ as a function of the estimated parameters from **Part 1**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from **Part 1** that $\\lambda$ is given by:\n",
    "$$\n",
    "\\lambda = \\frac{h}{(1-F_W(w^*;\\mu,\\sigma))}\n",
    "$$\n",
    "and that we can obtain $b$ from the equation for the reservation wage:\n",
    "$$\n",
    "w^* = b + \\beta \\lambda \\int_{w^*} \\frac{1-F_W(w)}{1-\\beta(1-\\delta)}dw\n",
    "$$\n",
    "$$\n",
    "\\implies b = w^* - \\beta \\lambda \\int_{w^*} \\frac{1-F_W(w)}{1-\\beta(1-\\delta)}dw.\n",
    "$$\n",
    "The following code backs out the parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-501.51164449347914"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "λ = pars.h / (1-cdf(pars.F,pars.wres))\n",
    "b = pars.wres - pars.β * λ * integrandGL(x -> dS(x;pars.F,pars.β,pars.δ),pars.wres,quantile(pars.F,0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Provide an estimate of the asymptotic variance of $(\\hat{h},\\hat{\\delta},\\hat{\\mu},\\hat{\\sigma},\\hat{w^*})$ using the standard MLE formula.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the standard errors, we can take advantage of the delta method. Specifically, it tells us that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 0.07870792169024328\n",
       " 0.09740231570648486\n",
       " 0.17253358400531876\n",
       " 0.042114134111141954\n",
       " 0.00843753864798779"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "H = ForwardDiff.hessian(x -> log_likelihood_obj(dx,pars,x),res.minimizer)\n",
    "N = length(dx.E)\n",
    "avar = inv(-H)\n",
    "se = sqrt.(diag(avar) / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can present a table of estimates and their standard errors:\n",
    "| Column 1 | Column 2 | Column 3 |\n",
    "| -------- | -------- | -------- |\n",
    "| Row 1    | Data     | Data     |\n",
    "| Row 2    | Data     | Data     |\n",
    "| Row 3    | Data     | Data     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recall that the delta method implies that if $\\hat{\\delta}$ is asymptotically normal with asymptotic variance $V$ then the vector-values function $F(\\hat{\\delta})$ is also asymptotically normal with:*\n",
    "$$\n",
    "\\sqrt{N}F((\\hat{\\theta})-F(\\theta)) \\xrightarrow{d} \\mathcal{N}(0,\\nabla_{\\theta'}FV\\nabla_{\\theta}F')\n",
    "$$\n",
    "*Use this fact to estimate the asymptotic variance of $(\\hat{h},\\hat{\\delta},\\hat{\\mu},\\hat{\\sigma},\\hat{w^*},\\hat{\\lambda},\\hat{b})$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now report all of your estimates and standard errors for this group. Repeat this exercise for each group.*\n",
    "\n",
    "*If we thought that the parametric relationship using $\\gamma$ from **Assignment 2** described the true values of the parameters for each group, how might we use these group-specific estimates to derive estimates of each $\\gamma$?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.1",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
